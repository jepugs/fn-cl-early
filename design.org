* Implementation and Bootstraps

  - Everything is implemented in Common Lisp. The only supported implementation
    is SBCL. No particular effort is made to maintain ANSI compliance, although
    most of the code is ANSI anyway.
  - Most of the code is in the FN-IMPL package. This package makes use of some
    features of FN (for instance, the $ reader macro), but we avoid shadowing
    any variables from the CL package.
  - The FN package is a drop-in replacement for the CL package that turns common
    lisp into FN.
  - There will be a standard library one day. It will initially be implemented
    entirely in FN and Common Lisp, but we would like to do a lot of it in C++
    (i.e. threads, networking, matrix operations) eventually.
  - At some point, I will likely reach the limit of what Common Lisp macros can
    easily do, and will need to begin the lengthy undertaking of writing a
    custom VM and interpreter. Beyond that, a dedicated compiler and FFI will
    eventually be desirable, so depending on how far I take this, we may need to
    reimplement the whole damn thing in C++.
  - The benefit to the current implementation of FN is that we can trivially use
    any Common Lisp libraries from FN source, so a crucial precondition to
    reimplementing the core language would be ensuring that it has a very rich
    standard library.


* Schemas and Patterns

  A schema describes an algebraic data type. They are used in pattern matching and
  by the new keyword.

  #+BEGIN_SRC common-lisp
  (defschema NAME &REST FIELDS) ; => nil

  (new NAME &REST FIELD-VALUES) ; => instance of NAME

  (@ INSTANCE FIELD) ; => value of FIELD in INSTANCE

  (match OBJ
    (NAME &REST VARS)
      EXPR
    ...)
  ;; => if OBJ matches the schema, bind the field values to VARS and execute 
  ;;    EXPR
  #+END_SRC


** Advanced Schemas

   Schemas are implemented in such a way that construction, access, and
   destructuring (i.e. pattern matching) can all be handled independently by
   general functions. This isn't especially useful in general, but it allows
   definition of special behaviors i.e. for dicts and linked lists.


** Schema Implementation

   Schemas are implemented via the schema class. Pertinent slots are:

   - name :: a symbol representing the name of the schema. This is used to
             identify it in constructors, accessors, and patterns and it *must*
             be unique in the schema table
   - data-class :: the class associated with the schema. This is used to
                   match schemas to instance objects, so it must be unique.
   - construct :: a function (f ARGS) that returns an instance of this Schema
   - access :: a function (f INSTANCE FIELD-NAME) that gets fields from the
               object
   - destruct :: a function (f PATTERN-ARGS OBJ) that returns a bindings object
                 or NIL


* New lambda lists

  Here's what we have in Common Lisp:

  #+BEGIN_SRC common-lisp
  (defun func (POSITIONAL-ARGS SPECIAL-ARG*) ...)
  #+END_SRC

  with

  - POSITIONAL-ARGS ::= SYMBOL*
  - SPECIAL-ARG ::= &rest SYMBOL | &whole SYMBOL | &body SYMBOL |
                    &key OPT-ARG* | &optional OPT-ARG*
  - OPT-ARG ::= SYMBOL | (SYMBOL VALUE)
 
  For now, we're going to completely nix &whole and &body. We will replace &rest
  directly with the symbol & (the ampersand by itself, like in Clojure). We
  replace &optional and &key with parenthesized forms as seen in the example
  below.

  #+BEGIN_SRC common-lisp
  (defun operator (operand0 &rest operands) ...)
  ;; => (in FN)
  (defun operator (operand0 & operands) ...)

  (defun log (x &optional (base 10)) ...)
  ;; => lists starting w/ non-keyword symbols replace &optional
  (defun log (x (base 10)) ...)

  (defun sort (seq &key (test #'< test-p) (ascending t)) ...)
  ;; => lists starting with keywords replace &key
  (defun sort (seq (:test #'< test-p) (:ascending t)) ...)
  #+END_SRC

  *Rationale:* I personally think argument lists in Common Lisp are too verbose
  and rather ugly because of it. By cutting out all of the &-symbols (except the
  rather intuitive & itself), the argument lists are shorter if nothing else. As
  a matter of taste, it also seems more LISP-y.

  *Key arg packages: a semantic gotcha:* In CL it is generally legal to use
  variables in an external package as function arguments. Our implementation of
  keyword arguments means that keyword symbol names will always appear in the
  package (sane-package). Since gensyms have null packages, this means that it
  is, for now, impossible to use them as names for keyword arguments. Of course,
  gensyms are generally useless as keyword arguments anyway, so this shouldn't
  matter.


* TODO:

  - implement dictionaries in dict.lisp
  - make PATTERN-VARS smarter
  - implement DEFN
  - implement protocols
  - set up syntax highlighting and indentation
  - schema index sets
  - add slices and iterators
  - add lazy lists and teach fold, map, and filter about them
  - add 


* Misc functions/macros

  - defschema
  - with-fields, with-fields*
  - match
  - dict
  - new
  - @
  - fold, map, filter, zip


* design ideas

  - parentheses denote code objects. quote and backquote return code objects
    that can be used by the program. Unquoted code is evaluated. Code objects
    are made out of primitive types, symbols, and conses.
  - square brackets are for lists (and consequently trees). Lists are singley
    linked in classic lisp fashion. We use the ampersand (&) instead of the dot
    for inline conses.
  - rejected idea (don't repeat this mistake): & is a function so (& a b c) :=
    [a b & c].
  - make objects with the keyword NEW. Schemas decide their own constructor
    parameters
  - Every schema has a corresponding pattern matcher
  - When looking up an object's schema, we will use the class name of the object
    as the key for a hash table. This is to make the lookup as fast as possible.


* Experimental Zone

  This is where I'm gonna put some wild ideas that I'm not sure about.

** matching in lambda lists (actually this feature sucks)

   In Common Lisp, we have these &-symbols for special arguments:

   #+BEGIN_SRC common-lisp
   (defun f (&optional fuck-me-sideways) ...)
   #+END_SRC

   But, we could also have these things:

   #+BEGIN_SRC common-lisp
   (defun f (&match [x y z]) ...)
   #+END_SRC

   which would do pattern-based destructuring on the argument.

   One problem is that we've nixed &-symbols in our version of defun, so we have
   parenthesized forms for variable names and keywords. Even then, it would be
   cumbersome to type &match before every pattern argument.


** unified definition

   First off, let's not kid ourselves: DEFPARAMETER is too long of a name.
   DEFVAR is not so bad, but usually we want DEFPARAMETER behavior, rather than
   DEFVAR behavior.
   
   Currently, I've decided to use DEF for declarations, SET for updates, CONST
   for constants, and DEFN for functions.

   #+BEGIN_SRC common-lisp
   (defparameter x 6)
   ;; => (in FN)
   (def x 6)

   (defconstant pi 3.14)
   ;; =>
   (const pi 3.14)

   (defun log (x &optional (base 10))
     ...)
   ;; =>
   (defn log (x (base 10))
     ...)
   ;; or, equivalently, (but not until the future)
   (def log
     (fn (x (base 10))
       ...))
   #+END_SRC


** function options

   Functions look like this:

   (fn (args) body)

   We would like to customize function behavior. If the first argument of the
   function body is a dict form (denoted below with braces), and the body has
   length > 1, then we will use that dictionary as the function options:

   (fn (args)
     {:option-name option-value ...}
     body)

   Some ideas for options are:

   - :type, :optimize, :ignore, ignoreable :: replace DECLARE forms
   - :inline BOOL :: whether to inline this function
   - :curry N :: automatically curry up the first N arguments. Or, if N is true,
                 then curry all positional arguments (default: false, eqv. 0)
   - :memo BOOL :: memoize the function if true (default: false)
   - :doc STR :: docstring (only in definitions)
   - :arg-doc LIST :: argument documentation (only in definitions)


** RADICAL: Immediate type syntax (Forget about QUOTE)

   *BIG note:* quote is useful within quasiquote, as we can write e.g.
   `(symbol-name ',x) to get a quoted version of a symbol within the quasiquote
   body. Otherwise we must write `(symbol-name (quote ,x)), which could get
   cumbersome quickly. Thus it's probably better not to touch this.

   Here we will explore syntax for immediate types. First, we will enumerate the
   essential types and their syntax in plain ol' CL

   - symbol :: 'sym or `sym
   - keyword :: :key
   - integer (base 10) :: 101
   - integer (base 16) :: #xb00b5
   - integer (octal) :: #o777
   - character :: #\c
   - float :: -1.237, 1.2938e9, etc
   - string :: "str"
   - bool :: T or NIL

   I would like it if we could do 0x2a for hexadecimal and 0o755 for octal.

   In addition, it would be possible, I think, to get rid of single quote for
   variables and simply use the backtick everywhere instead. Then, single quotes
   could be used for strings or characters, but this would really fuck with
   paredit so maybe it's a distant future sort of change. However, doing so
   would also let us reclaim the # character.


** Is this be a LISP-2?

   No. Well, it's not supposed to be. At the moment, there are still,
   unfortunately, relics of Common Lisp's silly old variable system. There's no
   easy way to declare global lexical variables, so we do our best.


*** Rationale


*** Implementation of Lexical Scope

    It's a lot of work to fake global lexical scope in Common Lisp, and the lack
    thereof is the single biggest problem I have with language. So, we do
    something a little whacky. We will override the left paren reader as
    described in the other Implementation section. This gives us the ability to
    have any expression in the operator position of a compound expresion. That's
    a good start.

    Whenever we define a global (non-dynamic) variable, we do a few things. We
    will also create a symbol macro with the same name that expands to
    (LEXICAL-VALUE 'SYMBOL). LEXICAL-VALUE itself is a magic macro that determines
    whether the variable is bound locally, and, if it is, expands to that
    symbol. Otherwise, it expands to get the LEXICAL-BINDING field from a
    symbol, which is where we put lexically bound variables.

    In addition to the LEXICAL-BINDING field of the symbol, we also set the
    function field for the symbol when the field is a function. This requires us
    to be very careful with how we mutate variables. That is, we must carefully
    set and unset the function field of a symbol when we change its value.
    Moreover, we have to be careful


*** Implementation 1

    A partial implementation is actually quite straightforward to implement in
    Common Lisp, but it involves changing the behavior of the reader macro for
    the left paren, which feels very dirty. I like it.

    Dumb jokes aside, the implementation would be easy and involve two steps.
    First of all, we would make DEF and DEFN assign both the variable and the
    function slots of a symbol. Then we redefine the left paren. The new reader
    would simply invoke the old one, check if the first item in the list is a
    symbol, and if it isn't, then expand it to a FN-FUNCALL form. FN-FUNCALL
    behaves like FUNCALL, except that it is also a compiler macro which will
    strip out CELL-VALUE calls (see the other implementation section), thereby
    eliminating the middle-man in 

    One problem we would run into is that code pulled in from other common lisp
    packages would not have its functions in the variable space, so we would
    still need to use the pointy #'FUN syntax for those guys. Provided there are
    no collisions in the exported symbols in function/variable space, it would
    be possible to automatically convert LISP-2 code to FN, but it probably
    isn't worth the trouble.


** Local definitions


* Immediate future

