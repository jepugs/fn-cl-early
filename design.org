* Introduction

fn is a programming language in the Lisp family. It will feature a robust and streamlined object
system, an intuitive module-based approach to code organization, powerful metaprogramming
facilities, and a variety of quality of life features that aid in writing especially concise code
without sacrificing clarity.

** fn compared to other dialects of Lisp

Compared to most dialects of Lisp, fn has a small number of special forms, several new syntactic
conveniences, and a strong focus on its native object system. The object system strives to avoid
several problems with CLOS, namely its feeling tacked-on to the rest of the language (because it
was) and being rather verbose.

In addition, fn code is homoiconic like Common Lisp, allowing writing of macros in the traditional
Lisp way, which I greatly prefer to the hygienic macros and templates of e.g. Racket or Scheme.
However, unlike Common Lisp, where even "properly-written" macros can break in the case of an
esoteric name collision, fn allows functions and variables to be looked up during macroexpansion in
order to avoid such issues. Thus the goals of hygiene may be achieved without resorting to using
special syntax objects or creating a pattern-based DSL.



** Implementation notes

- Everything is implemented in Common Lisp. The only supported implementation is SBCL. No particular
  effort is made to maintain ANSI compliance, although most of the code is ANSI anyway.
- This code is only tested on a handful of my personal computers, all of which run Arch Linux.
- I am currently in the process of rewriting fn. The previous version, which was nearly a feature
  complete version 0, was built as a layer on top of Common Lisp, using the Common Lisp reader and
  macros to implement almost all of its features. This new version will be a proper interpreter.


* Modules and Name Resolution

** Definition order

In fn, loading source files behaves as is they are evaluated one expression at a time from beginning
to end. Function and variable lookups may be performed at runtime, so a function may use a variable
or another function whose definition appears later in the file.

The same rules generally apply to macros, but with some gotchas. Macros may be defined in the same
file they are used in, but must be appear (lexically) before any uses. If a macro uses a function to
create its expansion, then that function must be defined before the macro is first expanded (duh)


** Modules

Right now, modules have a 1-to-1 correlation with fn source files. To import a file, you use import
with a symbol corresponding to the file name, without any extension.

#+BEGIN_SRC fn
;; imports from file "x.fn" and binds the module as x
(import x)
;; imports from file "x.fn" and binds the module as y
(import x 'as y)
;; imports from file "x.fn" and binds all variables locally
(import x 'as _)
#+END_SRC

Modules are first class objects and their variables may be accessed using ~get~ or dot syntax.

#+BEGIN_SRC fn
;; file my-module.fn
(def my-var 26)

;; file example-a.fn
(import my-module)
my-module.my-var ;=> 26

;; file example-b.fn
(import my-module 'as mod)
mod.my-var ;=> 26

;; file example-c.fn
(import my-module 'as _)
my-var ;=> 26
#+END_SRC


*** Accessing modules without imports

The function ~(find-module sym)~ can be used to search for modules at runtime (the argument ~sym~ is
evaluated). Additionally, the syntax ~#.sym~ (eqv. to ~(get # 'sym~)) is available as a shorthand for
module lookups.


*** Implementation note: modules, macros, and dynamic vars

In Common Lisp, importing a macro means importing a symbol from another package. E.g. I import ~LOOP~
from ~CL~ and now every time I type ~loop~ it gets silently converted to ~CL:LOOP~. This allows a
one-to-one correspondence between macros and the symbols that represent them. At evaluation time, we
are guaranteed that the operator for a macro expression will always be a symbol, and its just a
matter of looking in that symbol's macro binding slot. In ~fn~, we no longer have the guarantee that
the operator is a symbol, and we have first-class module objects instead of packages, so we need to
take a more sophisticated approach.

The interpreter will internally maintain a list of which symbols (if any) are bound to modules.
Then, to do macro expansion on a list, we perform two checks: first, whether it's a symbol bound to
a macro in the current module (duh). If not, we check next whether the operator is a ~get~ expression.
If it is, and its first argument is a symbol referencing an imported module, then we can check that
module for macro bindings as well. This allows painless use of macros from other modules.


*** Future extension: ~__modules.fn~

In the future, a file named ~__modules.fn~ may be added to a source directory in order to define
modules that don't correspond directly to files and to modify the search path on a per-project
basis. In addition, it will be possible to automatically define wrapper modules that import all
their variables from submodules in order to create cleaner interfaces.


** Dynamic variables

In fn, dynamic variables may be created using ~defvar*~. In keeping with lisp tradition, we
recommend naming dynamic variables with earmuffs. (No ~def*~ form is included, because all dynamic
variables need to be resolved, well, dynamically, so they might as well be mutable).

#+BEGIN_SRC fn
(defvar* *name* initial-value)
#+END_SRC

This declares ~*name*~ to be a dynamic variable. Dynamic variables may be rebound with ~let~.

#+BEGIN_SRC fn
(defvar *special-x* 27)

(def (get-value) *special-x*)

(get-value) ;=> 27
(let (*special-x* 420)
  (get-value) ;=> 420
  )
(get-value) ;=>27
#+END_SRC

IMPORTANT NOTE:* Unlike in other dialects of lisp, special variables must be declared before they
are treated as special. Uses prior to that point will be treated as normal lexical variables.
Example:

#+BEGIN_SRC fn
(def (call-with-square-0 fun x)
  (let (sq (* x x))
    (fun sq)))

(defvar* sq 16)

(def (call-with-square-1 fun x)
  (let (sq (* x x))
    (fun sq)))

(def (get-sq _) sq)

;; call-with-square-0 treats sq as a normal lexical variable because it was defined before sq was 
;; declared dynamic.
(call-with-square-0 get-sq 6) ;=>16

;; call-with-square-1 treats sq as a dynamic variable
(call-with-square-1 get-sq 6) ;=>36

#+END_SRC


* Functions

There are two special operators that create functions: ~fn~ and ~dollar-fn~. The latter is usually
written using dollar-sign syntax. The expression ~$(function-body)~ expands to ~(dollar-fn
(function-body))~.

#+BEGIN_SRC fn
  ;; syntax for fn is
  (fn (<parameters>) <body>)

  ;; there are three kinds of parameters recognized by fn: positional, keyword, and variadic.
  ;; Positional params are denoted by plain symbols and keyword params by quoted symbols. Variadic
  ;; parameters are defined by using the special symbol & followed by a symbol indicating the name of
  ;; the variable.

  ;; function that takes two positional arguments and sums their reciprocals
  (def sum-inv 
    (fn (x y)
      (+ (/ 1 x) (/ 1 y))))
  (sum-inv 0.5 0.2) ;; => 7

  ;; function that takes one positional argument and two keyword arguments. This function will 
  ;; apply the function if-num if v is a number, otherwise it will apply 'otherwise.
  (def apply-if-num
    (fn (v 'if-num 'if-not)
      (if (num? v)
          (if-num v)
          (if-not v))))
  ;; to call functions with keyword arguments, simply put the quoted symbols in the argument list
  (apply-if-num "hello" 'if-num String 'if-not println) ;; prints "hello"
  ;; keyword arguments may be provided in any order
  (apply-if-num 2 'if-not println 'if-num String) ;; => "2"

  ;; keyword and positional parameters can be made optional by putting them in parentheses followed 
  ;; by a default expression. Required parameters may not succeed optional ones.
  (def increment (num (by 1))
    (+ num by))
  (increment 17) ; => 18 (uses default value for by)
  (increment 17 2); => 18

  ;; variadic arguments must come last in an argument list.
  (def string-sum (& numbers)
    (String (apply + numbers)))

#+END_SRC

*** Wildcard parameters

Positional parameters using the wildcard symbol "_" are treated specially. Such parameters do not
cause any variables to be bound in the function body, i.e. the argument in the corresponding
position is ignored. These may also be used as optional arguments, although a dummy default value
must still be provided, e.g. ~(_ null)~


*** Variadic arguments and keywords

When a function accepts both keywords and variadic arguments, all the variadic arguments must be
alternating symbol and value pairs, just like normal keyword arguments. This behavior is very
similar to the behavior of combining ~&REST~ and ~&ALLOW-OTHER-KEYS~ in Common Lisp. The one difference
is that the property list bound to the variadic argument will not contain any of the explicitly
specified keyword parameters. That is:

#+BEGIN_SRC fn
(def (fun 'key1 & other-keys)
  other-keys)

;; other-keys will not contain the value for 'key1
(fun 'key1 4 'key2 6 'key3 8)
;; => ('key2 6 'key3 8)

#+END_SRC

Functions which accept both variadic arguments and keywords have argument checking done to make that
the keyword arguments form a plist. To get argument checking without having any explicit keyword
arguments, include "'_" (quote underscore) in the parameter list.

#+BEGIN_SRC fn
;; this function accepts any arguments
(def (fun1 & args)
  args)
;; so this is fine
(fun1 'key 2 3.14159 "hello" 'key2)

;; this function only accepts arguments that form a proper plist
(def (fun2 '_ & args)
  args)
;; this is an error
(fun2 'key 2 3.14159 "hello" 'key2)
;; but this is fine
(fun2 'key 2 'key2 "hello")

#+END_SRC


* Classes and Methods

fn is an object-oriented programming language. Every value in fn is an object, and every object is
an instance of some class, which describes the object's structure. Polymorphism is provided via
methods, which are callable objects that perform different actions based upon the classes of their
arguments.

** Anatomy of an Object

Objects are key-value stores where the keys are symbols called the *fields* of the object and the
values are arbitrary. In addition, every object has a *class* which may be accessed using the built-in
~class-of~ operator. The class contains a list the object's fields as well as a symbol representing
the class's name.


** Classes

Classes are defined using the ~defclass~ operator, which creates a global variable holding a ~Class~
object. Class objects are created based upon a parameter list. This parameter list serves two
functions. First, the variables in the parameter list denote the fields of the class. Second, the
constructor for the class(, invoked by calling the class as an object,) uses the parameter list to
process its arguments.

By convention, type names begin with capital letters.

#+BEGIN_SRC fn
;; class definition
(defclass (Class-Name & params))

;; to invoke the constructor, use call the class like a function
(Class-Name & args)

;; Access fields directly
(get-field obj 'field)
(set (get-field obj 'field) new-value)

;; Access fields via the generic accessors
(get obj 'field)
(set (get obj 'field) new-value)
;; or, equivalently,
obj.field
(set obj.field new-value)
;; this dot notation is preferred wherever possible

;; we can even get fields from the Class itself
(get Class-Name 'fields) ;=> params
(get Class-Name 'name) ;=> 'Class-Name


;; if Class were defined with defclass: (note: it wasn't and there's no constructor)
(defclass (Class name fields constructor))
(class-of class)
#+END_SRC

*** Future features

Options should allow customization of the object's internal representation, constructor, and fields.
E.g. fields may be marked mutable or have type restrictions applied.


** Polymorphism via Methods

fn provides polymorphism in the form of methods. fn's methods support multiple dispatch (i.e. they
are multimethods). The syntax is demonstrated below.

#+BEGIN_SRC fn
;; To define a multimethod, you must specify its name, a list of one or more dispatch parameters,
;; and a parameter list containing all the dispatch parameters.

(defmethod ((<name> <dispatch-params>) <params>))

;; Methods are implemented using def. Syntax is very similar to function definition except that
;; the name of the method and the dispatch types must also be specified.
(def ((<name> <dispatch-classes>) <params>)
  <implementation-body>)

;;; EXAMPLE: the call method (used to treat arbitrary objects as functions)
;; call does dispatch on the argument obj
(defmethod ((call obj) obj & args))

;; implementation of call on classes
(def ((call Class) class & args)
  (apply class.constructor args))

;;; EXAMPLE: the mul method used to extend multiplication.
;; mul does multiple dispatch on the arguments l and r
(defmethod ((mul l r) l r))

;; implement methods using def. Parameter names may be changed.
(def ((mul Num String) ct str)
  (loop (i res) (ct "")
    (if (= i 0)
        res
        (recur (- i 1)
               (append res str)))))

(def ((mul String Num) str ct)
  ;; simply flip the arguments 
  (mul ct str))

#+END_SRC

*** Implementation

Dispatch is done using hash tables. The keys are lists of Class objects.


** Built-in classes

The following classes are built into fn.

*Atomic types*
- Symbol :: symbol
- Bool :: boolean denoted ~true~ or ~false~
- Null :: unassigned value denoted ~null~
- Num :: 64-bit floating-point number

*Structure types*
- Class :: the type of types
- List :: singley-linked list
- String :: character string

(Hash-)tables, arrays, foreign data structures and byte arrays are planned for the future.


* Comprehensive language description

This section completely (and formal-ish-ly) describes fn as it is now. It is a work in progress, but
it's completion is a priority.

** Notation

Operators are documented using syntax that looks like this: ~(op <var1> <vars*>)~. In this example, op
is a literal code symbol, <var1> is a single user-specified expression, and <vars*> is an inline
sequence of other expressions. In general, the symbols in angle brackets are parameters for the
operator while unbracketed. A Kleene star (*) in angle brackets always indicates a sequence.

In addition, some names have more specific meanings:

- <body*> :: a series of one or more expressions constituting a valid function body
- <obj> :: is an expression yielding an arbitrary object
- <params*> :: an fn parameter list like those used in function creation


** Syntax
*** Literals

*** Symbols

*** Lists

*** Other syntax

*** BNF

Below is the BNF used to parse the language. It is presented as the same LR(1) grammar used by the
interpreter.

#+BEGIN_SRC
<program> ::= <expr>*
<expr>    ::= <atom>
            | <group>
            | <dot>
            | <dollar>
            | <quoted>
            | <unquoted>
            | <unquote-spliced>
            | <quasiquoted>

<atom> ::= <symbol> | <number> | <string>

<group>     ::= <list> | <brackets> | <braces>
<list>      ::= "(" <expr>* ")"
<brackets>  ::= "[" <expr>* "]"
<braces>    ::= "{" <expr>* "}"

<dot> ::= <dot-part> <symbol>
<dot-part> ::= <symbol> "." | <dot> "."

<dollar> ::= "$(" <expr*> ")"
           | "$[" <expr*> "]"
           | "${" <expr*> "}"
           | "$`" <expr>

<quoted>           ::= "'" <expr>
<unquoted>         ::= "," <expr>
<unquote-spliced>  ::= "," <expr>
<quasiquoted>      ::= "`" <expr>
#+END_SRC

Where <symbol> is a symbol, <number> is a number, and <string> is a string literal.


** Special operators

Below is a complete list of fn's special operators. Operators marked done are fully documented below
and implemented in the interpreter

*** DONE ~apply~

#+BEGIN_SRC fn
;;; syntax - apply
(apply <obj> <args*> <arg-list>)
;;; where
;; <obj> is a callable object
;; <args> 0 or more arguments to be passed to <fun>
;; <arg-list> a list of arguments to be passed to <fun>
#+END_SRC

~apply~ invokes an object's call method with elements of the provided list as arguments. If <args*>
are specified before <arg-list> then those arguments are prepended to the arg-list before calling.

*** TODO ~case~

*Impl. status:* ~case~ behavior is not yet fully specified.

*** DONE ~class-of~

#+BEGIN_SRC fn
;;; syntax - class-of
(class-of <obj>)
#+END_SRC

~class-of~ gets the class of an object.

*** DONE ~cond~

#+BEGIN_SRC fn
;;; syntax - cond
(cond <cond-clauses*>)
;;; where
;; <cond-clauses*> is a nonempty even-length sequence of expressions

;;; example:
(def (divisor-search x)
  (cond
    (= (mod x 2) 0) "2 divides x"
    (= (mod x 3) 0) "3 divides x"
    ;; this
    true "neither 2 nor 3 divides x"))
;; only the first truthy condition is used
(divisor-search 6) ;=> "2 divides x"
(divisor-search 12) ;=> "2 divides x"
(divisor-search 9) ;=> "3 divides x"
(divisor-search 5) ;=> "neither 2 nor 3 divides x"

#+END_SRC

~cond~ is a conditional construct. Each cond-clause is two expressions, a condition followed by a
result. Each condition is evaluated in the provided order until one of them evaluates to a truthy
value (i.e. anything other than ~false~ or ~null~). The result of this condition is evaluated and
returned. If no conditions succeed, then ~null~ is returned.

*** DONE ~def~

#+BEGIN_SRC fn
;;; syntax - def
(def <var> <obj>)                              ; var def
(def (<var> <params*>) <body*>)                ; function def
(def ((<method> <types*>) <params*>) <body*>)  ; method def
;;; where
;; <var> is an unbound symbol
;; <types*> is a non-empty sequence of symbols naming classes
;; <method> is a symbol naming a global method
#+END_SRC

~def~ has three forms that each perform a different action. The first form defines an immutable global
variable with the specified value. The second form creates a function named <var> with the provided
params and body. The third form defines a method implementation of <method> on the provided types.

*** DONE ~defclass~

#+BEGIN_SRC fn
;;; syntax - defclass
(defclass (<Name> <params*>) <options*>)
;;; where
;; <Name> is an unbound symbol used to hold the created class object
;; <options*> is a sequence of defclass options
#+END_SRC

~defclass~ creates a new global class object of the given name. The parameter list variables are used
as the class's fields and is also used to define the constructor.

At this time, there are no supported class definition options. Future extensions will allow
declaration of mutable/immutable fields, alternative constructor behavior, and so on.

*** DONE ~defmacro~

#+BEGIN_SRC fn
;;; syntax - defmacro
(defmacro (<var> <params*>) <body*>)
;;; where
;; <var> is a symbol
#+END_SRC

~defmacro~ defines a global macro (local macros do not presently exist in fn). The expansion function
takes the provided params and evaluates <body*>.

Macroexpansion is similar to function calling, except that macros accept and return code objects.
The arguments to a macro are not evaluated, but are quoted and passed directly to the expansion
function. The result of the macro is then evaluated in place of the original list.

Macros are not first class objects, and so they may share names with normal variables. This is
generally not a good idea, but can be useful in some cases (i.e. where a function can be
preprocessed based on its arguments to have a more efficient expansion).

*** DONE ~defmethod~

#+BEGIN_SRC fn
;;; syntax - defmethod
(defmethod ((<var> <dispatch-params*>) <params*>)
  <method-options*>)
;;; where
;; <dispatch-params*> is a sequence of symbols, all of which must appear as names in <params*>
;; <method-options*> is a sequence of method options, none of which are currently defined
#+END_SRC

~defmethod~ defines a new global method object, which is a callable object that has different behavior
depending on the classes of its arguments. The dispatch params determine which parameters are used
to decide the behavior. Method instances (i.e. specific functions for different combinations of
classes) are created using ~def~.

*** DONE ~defvar~

#+BEGIN_SRC fn
;;; syntax - defclass
(defvar <var> <obj>)
;;; where
;; <var> is an unbound symbol
#+END_SRC

~defvar~ defines global mutable variables.

*** TODO ~defvar*~

#+BEGIN_SRC fn
;;; syntax - defclass
(defvar* <var> <obj>)
;;; where
;; <var> is an unbound symbol
#+END_SRC

~defvar*~ defines global dynamic variables.

*Impl. status:* ~defvar*~ is not implemented

*** DONE ~do~

#+BEGIN_SRC fn
;;; syntax - do
(do <body*>)
#+END_SRC

~do~ evaluates the expressions in its body in the order in which they are provided, returning the
result of the last expression.

*** DONE ~dollar-fn~

#+BEGIN_SRC fn
;;; syntax - dollar-fn
(dollar-fn <expr>)
;;; where
;; <expr> is an expression which may contain $-syms

;;; equivalent syntax is
$<expr>
;; however, the dollar sign must not have any whitespace before the expression, and the expression
;; must start with one of these characters: (, [, {, or `.


;;; examples:
;; creates a function of two arguments that adds them
$(+ $0 $1)
;; creates a function of one argument that subtracts six
$(- $ 6)
#+END_SRC

~dollar-fn~ is mainly used via dollar-sign syntax. It provides a convenient notation for short
anonymous functions. To evaluate ~dollar-fn~, the code for <expr> is walked so that $-syms can be
found. $-syms are symbols ~$~, ~$0~, and ~$&~, plus all symbols of the form ~$n~, where ~n~ is a positive
integer with no plus sign or leading 0s, e.g. ~$2~ or ~$11~.

$-syms correspond to positional arguments in the created function. ~$~ and ~$0~ are equivalent, and
denote the first argument, ~$1~ denotes the second, and so on. When ~$&~ appears in the list, it is
bound to a list of all arguments after the last positional argument in the list.

The functions created by ~dollar-fn~ only accept as many arguments as are necessary. If the expression
only contains ~$~, the function will accept exactly one argument, while if its maximum-numbered $-sym
is ~$7~, it will accept at 8 arguments. An expression with ~$&~ will accept any number of arguments, and
a function with no $-syms will accept no arguments.

Nested occurrences of ~dollar-fn~ are not walked for $-syms in the outer ~dollar-fn~. This means that
nesting dollar-fn is legal, but no argument vars from the outer function can be accessed by the
inner function.

*** DONE ~fn~

#+BEGIN_SRC fn
;;; syntax - fn
(fn (<params*>) <body*>)
#+END_SRC

~fn~ creates an anonymous function which accepts the provided parameters and executes the code in
<body*>.

*** DONE ~get~

#+BEGIN_SRC fn
;;; syntax - get
(get <obj> <keys*>)
;;; where
;; <keys*> is a sequence of one or more objects used as keys for obj

;;; dot syntax expands into get expressions
<sym1>.<sym2>
;;; expands to
(get <sym1> '<sym2>)
;;; where <sym1> and <sym2> are both symbols
#+END_SRC

~get~ is used to access the contents of an object using the provided keys. If multiple keys are
provided, then ~get~ is applied recursively using each key in order.

Default behavior for ~get~ depends on the type of the object:

#+BEGIN_SRC fn
;;; strings
;; get a numerical index
(get "test" 1) ;=> "e"

;;; modules
;; gets variables from the module
(get <module> <var>) ;; value of a variable in a module

;;; In the future, vectors will be accessible by number and tables by arbitrary keys
#+END_SRC

However, for the majority of objects, including all instances user-defined classes, get simply
accesses the fields of thei object by their names.

*** DONE ~if~

#+BEGIN_SRC fn
;;; syntax - if
(if <obj>
    <then>
    <else>)
;;; where <then> and <else> are arbitrary expressions
#+END_SRC

~if~ is a conditional expression. If <obj> is not ~false~ or ~null~, then it evaluates <then> and returns
its value. Otherwise, it evaluates <else> and returns that value.

*** TODO ~import~

#+BEGIN_SRC fn
;;; syntax - import
(import <module>)
(import <module> 'as <name>)
;;; where
;; <module> is a module designator
;; <name> is a symbol
#+END_SRC

~import~ imports an external module as a global variable. The name of the created variable can be
provided via the 'as keyword parameter. It is <module> by default. Module import behavior differs in
interactive and non-interactive evaluation.

Importing a module non-interactively:

1. searches for <module> in the list of previously-imported modules
2. if <module> was loaded previously, reuse the existing module object.
3. otherwise, look in the search path for the file <module>.fn. 
4. If a file is found, initialize a new module object by evaluating it. Otherwise, emit an error.

In interactive mode, when a module is imported a second time, the timestamp of its source file is
checked. If the file has been modified since the last import, the module is reloaded.

The search path is ~./:/usr/local/lib/fn/modules/:/usr/lib/fn/modules/~. Paths are relative to the
directory of the file being evaluated.

*Impl. Status:* Import works, but currently overwrites existing module definitions regardless of mode.
Module names may not include slashes.

**** Future extension: filename imports

There need to be other ways to import modules. Perhaps strings could be used to indicate filenames: 

#+BEGIN_SRC fn
(import "../core/src.fn") ; automatically names the module src
src ;=><MODULE:src.fn>
(import "../core/src.fn" 'as local-mod)
#+END_SRC

*** DONE ~let~

#+BEGIN_SRC fn
;;; syntax - let
(let (<binding-specs*>)
  <body*>)
;;; where
;; <binding-specs*> is an even-length alternating sequence of symbols and expressions

;;; examples
(let (x 2
      y 3)
  (+ x y)) ;=> 5
;; example with a recursive function:
(let (f (fn (acc lst)
          (if (= lst [])
              acc
              (f (+ lst.hd acc) lst.tl))))
  (f 0 [1 2 3])) ;=> 6
#+END_SRC

~let~ is used to extend the current lexical environment with new variables. The body is evaluated
within the extension.

A binding specifier is a symbol followed by a value expression. Each binding specifier adds one
local variable with the provided symbol as a name. Its value is the result of evaluating the
expression.

When let is evaluated, the lexical environment is extended before any value expressions are
evaluated. This allows recursive function definitions. The value expressions are always evaluated in
the order they are provided provided.

*** DONE ~quasiquote~

#+BEGIN_SRC fn
;;; syntax - quasiquote
(quasiquote <expr>)
;;; or equivalently
`<expr>
;;; where <expr> is an arbitrary expression
#+END_SRC

~quasiquote~ performs quasiquotation of the provided expression. When applied to an ~unquote~
expression, that value of unquote expression is evaluated. When applied to a list, recurisvely
applies quasiquotation to the elements of the list. When applied to another type of expression,
quotes the expression.

In addition, a quasiquoted list may contain ~unquote-splice~ expressions. ~unquote-splice~ expressions
evaluated and return a list (an error is generated if the value is not a list). This list is spliced
into the rest of the quasiquoted list.

Nesting quasiquote changes unquote behavior. For each level of quasiquotation, an additional level
of unquotation is needed in order to trigger evaluation. Lower-levels of unquote and unquote-splice
expressions are quoted like normal lists.

*** DONE ~quote~

#+BEGIN_SRC fn
;;; syntax - quote
(quote <expr>)
;;; or equivalently
'<expr>

;;; examples:
;; quoting literals
'-2 ;=> -2
'"str" ;=> "str"
;; quoting symbols
'a ;=> a
'symbol ;=> symbol
;; quoting lists
'(+ 2 x) ;=> [+ 2 x]
'(String "x+3=" (+ x 3)) ;=> [String "x+3=" [+ x 3]]
#+END_SRC

~quote~ causes an expression's code to be returned as an fn value. This process is called *quoting*.

*** DONE ~set~

#+BEGIN_SRC fn
;;; syntax - quote
(set <var> <value>)
(set (get <obj> <keys*>) <value>)
#+END_SRC

~set~ is used to set variables and to mutate objects. When ~(set (get obj field))~ is used, the value of
field in object is mutated. Note that fields in user-defined classes are immutable by default, and
that all built-in classes are also immutable. (Note: tables and byte arrays will have mutable
fields).

*** DONE ~unquote~

#+BEGIN_SRC fn
;;; syntax - unquote
(unquote <expr>)
;;; or equivalently
,<expr>
#+END_SRC

~unquote~ is used within ~quasiquote~, where it causes its expression to be evaluated.

When ~unquote~ appears outside of ~quasiquote~, an error is generated.

*** DONE ~unquote-splice~

#+BEGIN_SRC fn
;;; syntax - unquote
(unquote-splice <expr>)
;;; or equivalently
,<expr>
#+END_SRC

~unquote-splice~ is used within quasiquoted lists, where it causes its expression to be evaluated and
spliced into the list.

When ~unquote-splice~ appears outside of a quasiquoted list, an error is generated.


** TODO Math functions

- +, -, /, *
- mod
- pow
- sqrt
- log
- floor
- ceil
- int-part
- frac-part
- int?
- even?
- odd?
- exp
- sin, cos, tan
- asin, acos, atan
- sinh, cosh, tanh
- asinh, acosh, atanh

** TODO Sequence functions

- head
- tail
- cons
- contains?
- nth
- take
- drop
- take-while
- drop-while
- map
- filter
- zip
- group
- group-by
- interleave
- reverse
- foldl
- foldr
- dedupe

*sequence creation*
- cycle
- repeat
- range

** TODO ~print~ and ~println~ (functions)

** TODO ~show~ (method)

** Built-in values
*** Classes

*** Functions

*** Methods

*** Macros


* Misc Notes and Ideas

This section is a bunch of garbage to help me remember things. I don't recommend trying to read
this.

** Compilation of method dispatch

To call a method:
- (?) check the arity of the method call
- evaluate the function arguments
- load a pointer to the dispatch function (from the method object)
- call the dispatch function with the provided arguments
- the dispatch function has been compiled to do this:
  - get the class of dispatch arguments with hard-coded indices
  - the next part must be recompiled every time a new implementation is added
  - there's a hard-coded dispatch hash table. The hash table uses an open addressing scheme. Every
    time a method is added, the table needs to be recompiled, but that's ok, because it should be
    rare to add another method at runtime anyway. Each bucket in the hash table corresponds to a
    location in the code, represented as an offset from some base pointer. At each location, the key
    is hardcoded in in the form of an equality test that jumps to probing if the keys are not equal.
    Linear probing is used to handle collisions. We could probably rebuild the table whenever the
    probe number exceeds a certain value. The idea here is that most methods will only have a few
    implementations.


** Proposal: implementing module (w/ reloading)

First change: add several functions for dealing with get expressions. Modules now know where they
were defined. If a module is being reloaded, we allow it to be fully redefined with a new module
object and all.


** Proposal: module names and paths

Module search path should be ~./:/usr/local/lib/fn/modules:/usr/lib/fn/modules~. I will hard-code this
for now.

There are several ways to import another module:

#+BEGIN_SRC fn
;; import creates a module variable
(import sym)
(import sym-or-string 'as name)
;; import-from binds the specified names in the current module
(import-from sym-or-string (names))
#+END_SRC

Note that modules may be imported using either symbols or strings. In the latter case, the string
should be the pathname (either relative or absolute) of an fn source file, including the extension.
If a symbol is used, then the module is equal to 

*Impl. note:* import-from should use the same value cells in the new bindings as in the original
module. This causes changes from one variable to propagate to changes from another.


** Proposed pattern matching behavior

#+BEGIN_SRC fn
;;; syntax - case
(case <obj>
  <case-clauses*>)
;;; where
;; <case-clause> ::= <pattern> <expr>
#+END_SRC

A pattern is an expression that describes the structure of an object. A typical format for a pattern
is this:

#+BEGIN_SRC fn
(<class-name> <class-args>) 

;; e.g.
(defclass (Vec2 x y))
(def (on-axis? v)
  (case v
    (Vec2 0 _) true
    (Vec2 _ 0) true
    (Vec2 _ _) false))

(on-axis? (Vec2 3 0))   ;=> true
(on-axis? (Vec2 0 -2))  ;=> true
(on-axis? (Vec2 3 1))   ;=> false
(on-axis? 0)            ;=> runtime error
#+END_SRC

Unlike ~cond~, case will throw a runtime error if there are no matches.


** Proposed extension: ~let~ pattern destructuring

#+BEGIN_SRC fn
;; code using current version of let
(let (left-right (split "foo,bar" ",")
      left left-right.hd
      right (get left-right 1))
  (String left " & " right)) ;=> "foo & bar"

;; proposed extension
(let ([left right] (split "foo,bar" ","))
  (String left " & " right)) ;=> "foo & bar"
#+END_SRC

In this extension, we allow ~case~-like pattern destructuring in ~let~ bindings.

A practical use of this extension would be to simulate multiple return values as shown in the
example above. A function with multiple return values would simply return them as a list, and ~let~
destructuring would make it convenient to recover the individual variables.

*** Q: Which patterns do we allow?

The one obvious requirement for patterns in let is that they have to bind variables.

There are three proposed "logical" patterns to be accepted by ~case~: ~satisfies?~, ~and~, and ~or~. The
first takes a function as an argument and matches if the function returns true when called with the
object as an argument. ~satisfies?~ binds no variables. ~and~ matches when all the patterns in its
arguments match and binds the last pattern's variables. ~or~ matches when any of the patterns in
its arguments match and binds no variables.

~let~ will not accept any logical patterns, as their behaviors are outside the scope of local variable
definition.


** Possible Alteration to Class/Object Structure

Ok so hear me out.

We have tables and structures (classes). Structures basically are tables but all the keys are
symbols. The problem is dot syntax. Right now it calls ~(get obj 'key)~ but we'd rather that it called
~(get-field obj 'key)~. Problems with this is that dot syntax is used to descend into module objects
so we need to differentiate somehow.

The current solution is this: provide a method, get-method, and use it to handle calls to get.
Problem with this is that it makes every access operation have to do virtual dispatch. Yuck.

Virtual dispatch works like this, by the way:
- get the class of each dispatch arg
- hash the list of classes to find the appropriate implementation function
- call the function


Potential Solutions:

- change the behavior of get so that it doesn't invoke get-method
  - in this case, there's no way to get the meta data of a module without (a) introducing special
    module variables like ~__name__~ and ~__fields__~ (Python style) or (b) providing a different
    special form/object type like ~(module-data <module>)~.
  - this would make Tables and Modules into the only special classes that have different behavior
  - alternatively, could turn all objects into generalized kv stores and encode ~__class__~ as a field
    in each object. This would beg for a reimagining of what a class is and would probably be hard.
- change the behavior of dot so that it has a different expansion (e.g. dotted-get)


** Standard library

If you think about it, lazy lists and iterators are almost the same thing. They both compute the
next value in a sequence. The main difference is that lazy lists have their intermediate results
saved. This allows the same lazy list object to be used in multiple places while guaranteeing that
each element will be evaluated at most once, and that unused elements will be evaluated never.

Both of these constructs have the advantage of allowing sequence operations to be composed in a very
efficient manner.

It is fairly easy to go from one representation to another. 


#+BEGIN_SRC fn
(defclass (Iterator head next))

(def (iter->list iter)
  (loop (acc i) ([] iter)
    (if iter
        (recur (cons i.head acc) (i.next))
        (reverse acc))))

(defclass (LCons hd tl))
(defclass (Lazy-List thunk))

(def ((head Lazy-List) seq)
  (case (seq.thunk)
    (LCons hd _) hd
    _            null))
(def ((rest Lazy-List) seq)
  (case (seq.thunk)
    (LCons _ tl) tl
    _            seq))

(def ((cons Lazy-List) hd tl)
  (let (x (LCons hd tl))
    (Lazy-List (fn () x))))



;; take and drop preserve the type of their sequence

;; filter and map return lazy lists
(def (map fun & lsts)
  (if (any empty? lsts)
      (Lazy-List [])
      (lcons (apply fun (map head lsts))
             (Lazy-List $(apply map fun (map tail lsts))))))



#+END_SRC

Math module:

- floor, ceil, round, frac (a.k.a fractional part)
- sin, cos, tan, sinh, cosh, tanh, asin, acos, atan
- exp, pow, log
- +, -, *, /, mod
- with-modulus (macro, locally rebinds +, -, *, and pow exprs to do modular arithmetic)


Sequence library:

- any, every
- cons
- (method) append
- (method) get-iter
- (class) Iter
- (class) Lazy-List
- map, foldl, foldr
- (replace subseq new-place seq)
- (split subseq seq)
- take, drop, take-while, drop-while, split, split-at


** Transducers vs Lazy Lists

Transducers are functions that transform reduction functions. map and filter are examples of
reduction functions. Because these examples produce lists as their output, they are composable as
transducers. For instance, a filter transducer would take a reduction function and apply it /after/
applying the filter to the input sequence. A map transducer applies the mapping function before
calling the transducer it's applied to. And so on.

Transducers and lazy lists both allow reduction functions to be composed before their results are
computed.

Pros of transducers over lazy lists:
- transducers are just functions
- no new sequence data structures are required
- don't need to save a new cons cell for every computation
- clojure does this
- simpler implementation because no memoization is needed

Pros of lazy lists over transducers:
- transducers compose in backwards order
- the usual reduction functions (map, filter, etc) compose more intuitively using lazy lists
- python does this
- could use iterators in place of full lazy lists

Efficiency: a transducer can be called lazily, so let's assume it is. Both approaches will then
generate one sequence element at a time. To get this element, here's what happens:

td
- the FIRST transducer in the composition chain consumes elements and passes them to
  the second
- and so on
- the FINAL transducer generates an object and returns it
- this chain is evaluated lazily so that the initial input will only be processed up to the point
  where the first element in the final output is generated

- the last transducer in the chain must be lazy

llist
- the LAST lazy list function in the composition chain is asked to compute its head
- this function's input is another lazy list, so we ask for elements from that lazy list. Each
  element we request is saved in a cons cell along the way. Once we've consumed all these elements
  from the intermediate list, they are garbage and can be collected.
- the second-to-last composed function asks for elements from the third  and so on

- a lazy cons cell holding a function is returned
- the intermediate value is computed and saved to the cons cell
- the cons cell is thrown away after the next value is used

So, every time an intermediate operation produces an object, one intermediate lazy cons cell is
created.

Third choice: iterators. It is possible to just create lazy iterator objects which don't have any
cons cells. This may be an appealing option.


** Version 0 Spec

If anyone other than me ever tries to read this, I'm sorry. This is a "complete" specification of
version 0 of the fn programming language (i.e. complete enough for me, the language designer, to
remember the decisions I've made so far).

*** Macros

#+BEGIN_SRC fn
;; define a macro
(defmacro NAME (ARG-LIST...)
  "Doc string"
  MACRO-BODY)
#+END_SRC

Macros work in the usual lisp way, and they are unsanitary. Macro functions may return function
objects as part of their outputs. This is encouraged as a way to prevent lexical variable
definitions from colliding with global module or function names.

*Note:* In the future, some facility e.g. a ~global~ special form may be introduced which allows global
variables to be accessed from macros without needing to include them as literals. Such a form would
possibly return a pointer object that unambiguous denoted the variable being referenced.


*** Syntax

Syntax is standard lisp parenthesized prefix notation. The following are all the special syntax
characters:

$()[]{}\;"',.

all other non-whitespace characters are symbol constituents, that is, they are parsed as atoms, i.e.
as symbols or numbers.


**** Delimiters

In typical lisp fashion, () are the delimiters denoting lists. In addition, [] and {} are matched
delimiters for reading lists and dicts. In fact, they are converted by the reader.

[a b c] -> (List a b c),
and
{:a 0 :b 1} -> (Dict :a 0 :b 1)

Also, "" reads UTF-8 strings. It uses C/C++ escape sequences because those are better than the lisp
ones and support Unicodes. Get over it.


**** Comments

There are no multi-line comments in fn. Only line-end comments, started by semicolons, are
supported.


**** Quotation

Normal quote works as it usually does in Lisp. Quasiquote works the same but lacks a destructive
splice.


**** Escaping

Escaping is when a backslash (\) character is placed in front of another character, thereby turning it
into a symbol constituent.. Any character can be escaped in any context except for within a string, (where string
escaping rules apply instead).


** idea: global pointers

I think it would be very useful to introduce a "pointer" data type (a better name might be GUID,
place, or address) which is simply an unambiguous reference to some global variable (possibly also
local?). GUID syntax could start with #G (or something) and would be very much analogous to symbols
in Common Lisp, in that GUIDs, like CL's symbols, would be standalone places to store objects. This
also allows an elegant alternative to gensyms, i.e. randomly-generated, disposable places.


** Version 0 grammar

#+BEGIN_SRC haskell
program -> expr* EOF
expr    -> constant
         | compound
         | unary
         | dot

constant -> STRING
          | NUMBER

compound -> paren
          | bracket
          | brace
paren    -> "(" expr* ")"
bracket  -> "[" expr* "]"
brace    -> "{" expr* "}"

unary      -> quote
            | quasiquote
            | unquote
            | unquote-splicing
            | dollar
quot       -> "'" expr
quasiquot  -> "`" expr
unquot     -> "," expr
unquot-splice -> ",@" expr
dollar     -> "$(" expr* ")"
            | "$[" expr* "]"
            | "${" expr* "}"
            | "$" quasiquote

dot -> SYMBOL "." SYMBOL
     | dot "." SYMBOL
#+END_SRC

#+BEGIN_SRC common-lisp
  (defun token-is? (tok kind)
    (eq (token-kind tok) kind))

  (make-parser
   ;; first form is grammar
   ((program -> (* expr) @eof)
    (expr -> constant / group / unary / dollar / dot)

    (constant -> @string / @number)

    (group -> paren / bracket / brace)
    (paren -> @left-paren (* expr) @right-paren)
    (bracket -> @left-bracket (* expr) @right-bracket)
    (brace -> @left-brace (* expr) @right-brace)

    (unary -> quot / quasiquot / unquot / unquot-splicing)
    (quot -> @quot expr)
    (quasiquot -> @backtick expr)
    (unquot -> @comma expr)
    (unquot-splice -> @comma-splice expr)

    (dollar -> @dollar-paren (* expr) @right-paren
            / @dollar-bracket (* expr) @right-bracket
            / @dollar-brace (* expr) @right-brace
            / @dollar-backtick expr)

    (dot -> var / dot @dot var)
    (var -> @symbol))

   ;; remaining forms are callbacks for nonterminals. Whenever a reduce is performed, the callback
   ;; corresponding to the generated nonterminal is invoked with a single argument, a list of the
   ;; POBJs used to make this pattern.
   (constant #'constant-fun)
   (dot #'dot-fun)
   (var #'var-fun)
   )

#+END_SRC


** Alternative: Virtual Memory and Built-in tags

I don't think I'll do this because keeping full 64-bit pointers would make foreign code interop and
low-level code writing much easier.

Suppose we limit ourselves to 56-bit pointers, which is still more than enough memory. Then, we have
8 bytes of the string which we can use as a type tag. We can use a variable-length tagging scheme to
get 62-bit fixed-width integers and if we pick tag 00 (binary) for those, we can use CPU native
integer arithmetic operations. It would also be possible to truncate 64-bit floating point numbers
to 62-bit precision by dropping the two rightmost digit, allowing use of x87 hardware and making
passing around of numbers, etc, much more efficient. A downside of this approach is that it would
give us less than the maximum 256 possible type tags that exist right now.


** Proposal: Multipass optimization

First pass would macroexpand and then evaluate all the forms in order. After this first pass, we
would have all of this information:

- types of all immutable global variables
- function parameter lists
- fully macro-expanded function bodies

Some nice things we could do next:

- replace (global, non-dynamic) variables with direct references to their value cells
- replace local variable environments with numeric arrays, allowing direct access of local variable
  cells
- 

** Proposal: Method generalization

#+BEGIN_SRC fn
(def ((add-method String (or Int Float)) left right)
  (append left right))
#+END_SRC
